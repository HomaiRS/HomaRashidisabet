<!DOCTYPE HTML>
<html>

<head>
  <title>Research</title>
  <meta name="description" content="website description" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=windows-1252" />
  <link rel="stylesheet" type="text/css" href="style/style.css" />

  <link rel="stylesheet" type="text/css" href="style/style.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">



<!--
      BODY OF RESEARCH
 -->
<body>
  <div id="main">
    <div id="header">
      <div id="logo">
        <div id="logo_text">
          <h1>Homa Rashidisabet</h1>
        </div>
      </div>
      <div id="menubar">
        <ul id="menu">
          <!-- <li>                  <a href="Project.html">      Project       </a></li> -->
          <li>                  <a href="vita.html">      Vita       </a></li>
          <!-- <li>                  <a href="email.html">     Email      </a></li> -->
          <li>                  <a href="Presentation.html">  Presentation     </a></li>
          <li class="selected"> <a href="research.html">  Research   </a></li>
          <li>                  <a href="index.html">     Home       </a></li>
        </ul>
      </div>
    </div>
    <div id="site_content_wide">

    <h3 style="padding:0;margin: 0;font-weight: bold;">Peer-reviewed journal papers </h2>



                <!--
                            Item
                -->
                <div class="container">
                      <div id="year">
                        <div id="yearItem"> April 2020 </div>
                      </div>
                      <div id="publisher">
                        <div id="publisherItem">   </div>
                      </div>
                      <div id="paperTitle">
                        <div id="paperTitleItem">
                            A systems biology approach to the digital behaviorome.
                            <i>
                              Rashidisabet, H., Thomas, P., Ajilore, O., Zulueta, J., Moore, R., Leow, A.
                            </i>
                            <b>
                                <i>(Published in Elsevier Journal of Current Opinion in Systems Biology). </i>
                            </b>
                        </div>
                      </div>

                      <div id="relatedLinks">
                              <!--link-->
                              <a href="https://doi.org/10.1016/j.coisb.2020.07.003" target="_blank">
                                <i id=activeLink  class="fa">&#xf0c1;</i>
                              </a>
                      </div>

                        <div id="abstract">
                            <div class="content">
                                <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                                <b> Abstract: </b>
                                  This review article summarizes how emerging connected technologies (e.g., smartphones and wearables) may provide
                                  novel avenues to understand an individual's behavior through the lens of systems biology. First, we surveyed
                                  recent research efforts that leveraged the multimodal high temporal resolution data derived from connected devices
                                  to build digital phenotypes and/or discover digital biomarkers of the behaviorome. We write this review with a
                                  particular emphasis on the detection, diagnosis, and symptom monitoring of neuropsychiatric disorders, as these
                                  pathologies may manifest primarily as disruptions to the behaviorome. We then discussed new opportunities and
                                  challenges these state-of-art research efforts bring as they intersect with other areas of natural and social
                                  sciences. Ultimately, we suggest how incorporating systems biology and connected technologies data can lead to
                                  a better understanding of complex neuropsychiatric disorders.
                              </p>
                            </div>
                            <a role="button" href="#" class="js-show-more">Show more</a>
                          </div>
                      </div>

        <!--
                Item
        -->
        <div class="container">
              <div id="year">
                <div id="yearItem"> July 2020 </div>
              </div>
              <div id="publisher">
                <div id="publisherItem"> Published in Journal of the American Medical Informatics Association.  </div>
              </div>
              <div id="paperTitle">
                <div id="paperTitleItem">
                  Effects of mood and aging on keystroke dynamics metadata and their diurnal patterns in a
                  large open-science sample: A BiAffect iOS study.
                    <i>
                      Vesel, C., Rashidisabet, H., Zulueta, J., Stange, J., Duffecy, J., Hussain,
                      F., Piscitello, A., Bark, J., Langenecker, S., Young, S., Mounts, E., Omberg, L.,
                      Nelson, P., Moore, R., Koziol, D., Bourne, K., Bennett, C., Ajilore, O., Demos, A., Leow, A.
                    </i>
                </div>
              </div>

              <div id="relatedLinks">
                      <!--link-->
                      <a href="https://doi.org/10.1093/jamia/ocaa057" target="_blank">
                        <i id=activeLink  class="fa">&#xf0c1;</i>
                      </a>
              </div>

              <div id="abstract">
                  <div class="content">
                    <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                    <b> Abstract: </b>
                    <br />
                    <b> Objective </b>
                    Ubiquitous technologies can be leveraged to construct ecologically relevant metrics that
                    complement traditional psychological assessments. This study aims to determine the feasibility
                    of smartphone-derived real-world keyboard metadata to serve as digital biomarkers of mood.
                    <br />
                    <b> Materials and Methods </b>
                    BiAffect, a real-world observation study based on a freely available iPhone app, allowed the
                    unobtrusive collection of typing metadata through a custom virtual keyboard that replaces the
                    default keyboard. User demographics and self-reports for depression severity (Patient Health
                    Questionnaire-8) were also collected. Using &gt 14 million keypresses from 250 users who reported
                    demographic information and a subset of 147 users who additionally completed at least 1 Patient
                    Health Questionnaire, we employed hierarchical growth curve mixed-effects models to capture the
                    effects of mood, demographics, and time of day on keyboard metadata.
                    <br />
                    <b> Results </b>
                    We analyzed 86 541 typing sessions associated with a total of 543 Patient Health Questionnaires.
                    Results showed that more severe depression relates to more variable typing speed (<i>P</i> < 0.001), shorter
                    session duration (<i>P</i> < .001), and lower accuracy (<i>P</i> < .05). Additionally, typing speed and variability
                    exhibit a diurnal pattern, being fastest and least variable at midday. Older users exhibit slower and
                    more variable typing, as well as more pronounced slowing in the evening. The effects of aging and time
                    of day did not impact the relationship of mood to typing variables and were recapitulated in the 250-user group.
                    <br />
                    <b> Conclusions </b>
                    Keystroke dynamics, unobtrusively collected in the real world, are significantly associated with mood despite
                    diurnal patterns and effects of age, and thus could serve as a foundation for constructing digital biomarkers.
                  </p>
                </div>
                <a role="button" href="#" class="js-show-more">Show more</a>
                </div>
            </div>



    <!--
         Working Papers
    -->
        <div class="container">

            </div>
              <h3 style="padding:0;margin: 0; font-weight: bold;"> Under-review papers </h2>

              <div class="container">
                    <div id="year">
                      <div id="yearItem"> April 2022 </div>
                    </div>
                    <div id="publisher">
                      <div id="publisherItem"> Opthalmology Science Journal- special call for AI papers.  </div>
                    </div>
                    <div id="paperTitle">
                      <div id="paperTitleItem">
                          Validating the generalizability of ophthalmic Artificial Intelligence models on real-world clinical data.
                      </div>
                    </div>

                    <div id="relatedLinks">
                            <!--link-->
                              <i id=inactiveLink  class="fa">&#xf0c1;</i>
                              <span style="display:inline-block; width: 2px;"></span>

                    </div>

                      <div id="abstract">
                          <div class="content">
                              <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                              <b> Abstract: </b>
                                Over the past decade, with promising results of Deep Learning (DL) in computer vision, the applications in ophthalmic imaging data have been increasing exponentially. However, overfitting and lack of generalizability are always a concern when DL models are developed over a single data set. Many of the past Computer Aided Diagnosis (CAD) studies have used standardized publicly available datasets having similar properties while almost none of them follows the complex characteristics of Real-World (RW) data. We study the generalizability of AI models trained on public versus RW data for two different popular tasks in ophthalmology research including glaucoma classification and Optic Disc (OD) segmentation. We used Illinois Eye and Ear Infirmary fundus dataset as an example for RW data along with six well-studied publicly available fundus datasets. We showed that even though public trained models have the highest accuracy on public data (0.88% for glaucoma classification, and 0.94% for OD segmentation), their accuracy drops by 16% and 8% for each task when the model was tested on the RW data. However, RW trained model performs stably across all datasets and its performance generalizes to both public and RW data verified on both tasks. Our work suggests that the standardized publicly available data are not a good representation of the RW data, and the models trained on them cannot effectively generalize to RW data. 
                            </p>
                          </div>
                          <!-- <a role="button" href="#" class="js-show-more">Show more</a> -->
                        </div>
                    </div>
      </div>

      <div class="container">
            <div id="year">
              <div id="yearItem"> May 2022 </div>
            </div>
            <div id="publisher">
              <div id="publisherItem"> Journal of Glaucoma.  </div>
            </div>
            <div id="paperTitle">
              <div id="paperTitleItem">
                  Association of Optical Coherence Tomography–based structural parameters with Visual Field progression in glaucoma patients.
              </div>
            </div>

            <div id="relatedLinks">
                    <!--link-->
                      <i id=inactiveLink  class="fa">&#xf0c1;</i>
                      <span style="display:inline-block; width: 2px;"></span>

            </div>

              <div id="abstract">
                  <div class="content">
                      <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                      <b> Abstract: </b>
                      Primary open-angle glaucoma (POAG) is a leading cause of irreversible vision loss worldwide.
                      POAG patients are typically unaware of their visual field (VF) abnormality; therefore, it is
                      critical to identify progressive glaucoma for early and adequate intervention. Before the advent of optical coherence tomography (OCT), glaucoma progression relied on assessments of the optic nerve during clinical examination and VF analysis over time. However, these assessments were subjective and qualitative, thereby limiting accuracy of detecting severity of glaucoma. The introduction of OCT imaging has provided accurate and detailed quantitative information of various retinal layers. The objective of our study is to systematically review and succinctly analyze studies that correlate OCT-based parameters with VF progression in glaucoma suspect and/or POAG patients. Finally, we discuss gaps in our current understanding of glaucoma management and propose directions for future studies.
                    </p>
                  </div>
                  <!-- <a role="button" href="#" class="js-show-more">Show more</a> -->
                </div>
            </div>
  </div>


  <!--
       Working Papers
  -->
      <div class="container">

          </div>
            <h3 style="padding:0;margin: 0; font-weight: bold;"> Working papers </h2>

              <!--
                      Item
              -->
              <div class="container">
                    <div id="year">
                      <div id="yearItem"> Present </div>
                    </div>
                    <div id="publisher">
                      <div id="publisherItem">   </div>
                    </div>
                    <div id="paperTitle">
                      <div id="paperTitleItem">
                        Unobtrusive detection of depression relapse from in-the-wild actigraphy data using a deep learning-based
                        multi-variate timeseries anomaly detection method.
                          <i>
                            Li, Q., Raghavan, N., Rashidisabet, H., Vairavan, S., Narayan, V., Kennedy, S.
                          </i>
                          <b>
                              (A collaborative journal paper with JnJ company).
                          </b>
                      </div>
                    </div>

                    <div id="relatedLinks">
                            <!--link-->
                              <i id=inactiveLink  class="fa">&#xf0c1;</i>
                              <span style="display:inline-block; width: 2px;"></span>
                    </div>

                    <div id="abstract">
                        <div class="content">
                            <p class="js-excerpt excerpt-hidden">

                          </p>
                        </div>
                        <!-- <a role="button" href="#" class="js-show-more">Show more</a> -->
                    </div>
                </div>
    </div>


<script src="style/scripts.js"></script>
</body>
</html>

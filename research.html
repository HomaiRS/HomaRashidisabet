<!DOCTYPE HTML>
<html>

<head>
  <title>Research</title>
  <meta name="description" content="website description" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=windows-1252" />
  <link rel="stylesheet" type="text/css" href="style/style.css" />

  <link rel="stylesheet" type="text/css" href="style/style.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">



<!--
      BODY OF RESEARCH
 -->
<body>
  <div id="main">
    <div id="header">
      <div id="logo">
        <div id="logo_text">
          <h1>Homa Rashidisabet</h1>
        </div>
      </div>
      <div id="menubar">
        <ul id="menu">
          <!-- <li>                  <a href="Project.html">      Project       </a></li> -->
          <li>                  <a href="vita.html">      Vita       </a></li>
          <!-- <li>                  <a href="email.html">     Email      </a></li> -->
          <li>                  <a href="Presentation.html">  Presentation     </a></li>
          <li class="selected"> <a href="research.html">  Research   </a></li>
          <li>                  <a href="index.html">     Home       </a></li>
        </ul>
      </div>
    </div>
    <div id="site_content_wide">

    <h3 style="padding:0;margin: 0;font-weight: bold;">Journal publication </h2>


      <!--
                  Item
      -->
      <div class="container">
            <div id="year">
              <div id="yearItem"> Nov 2023 </div>
            </div>
            <div id="publisher">
              <div id="publisherItem">   </div>
            </div>
            <div id="paperTitle">
              <div id="paperTitleItem">
                  Validating generalizability of ophthalmic Artificial Intelligence models on real-world clinical data.
                  <i>
                    Rashidisabet, H., Sethi, A., Jindarak, B., Edmonds, D., Chan, P., Vajaranant, T., Yi, D.
                  </i>
                  <b>
                      <i>Translational Vision Science & Technology</i>
                  </b>
              </div>
            </div>

            <div id="relatedLinks">
                    <!--link-->
                    <a href="https://tvst.arvojournals.org/article.aspx?articleid=2792985" target="_blank">
                      <i id=activeLink  class="fa">&#xf0c1;</i>
                    </a>
            </div>

              <div id="abstract">
                  <div class="content">
                      <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                      <b> Abstract: </b>
                      <br />
                      <b> Purpose </b>
                      This study aims to investigate generalizability of deep learning (DL) models trained on commonly used public fundus images to an instance of Real-World Data (RWD) for glaucoma diagnosis.
                      <br />
                      <b> Methods </b>
                      We used Illinois Eye and Ear Infirmary fundus dataset as an instance of RWD in addition to six publicly available fundus datasets. We compared the performance of DL-trained models on public data and RWD for glaucoma classification and Optic Disc (OD) segmentation tasks. For each task, we created models trained on each dataset, respectively, and each model was tested on both datasets. We further examined each model's decision-making process and learned embeddings for the glaucoma classification task.
                      <br />
                      <b> Results </b>
                      Using public data for test set, public-trained models outperformed RWD-trained models in OD segmentation and glaucoma classification with mean Intersection over Union (IoU) of 96.3% and mean Area Under the Receiver Operating Characteristic Curve (AUROC) of 95.0%, respectively. Using the RWD test set, the performance of public models decreased by 8.0% and 18.4% to 85.6% and 76.6% for OD segmentation and glaucoma classification tasks, respectively. RWD models outperformed public models on RWD test sets by 2.0% and 9.5%, respectively, in OD segmentation and glaucoma classification tasks.
                      <br />
                      <b> Conclusions </b>
                      DL models trained on commonly used public data have limited ability to generalize to RWD for classifying glaucoma. They perform similarly to RWD models for OD segmentation.
                      <br />
                      <b> Translational Relevance </b>
                      RWD is a potential solution for improving generalizability of DL models and enabling clinical translations in care of the prevalent blinding ophthalmic conditions, such as glaucoma.
                    </p>
                  </div>
                  <a role="button" href="#" class="js-show-more">Show more</a>
                </div>
            </div>

      <!--
                  Item
      -->
      <div class="container">
            <div id="year">
              <div id="yearItem"> Oct 2023 </div>
            </div>
            <div id="publisher">
              <div id="publisherItem">   </div>
            </div>
            <div id="paperTitle">
              <div id="paperTitleItem">
                  Personalized relapse prediction in patients with major depressive disorder using digital biomarkers.
                  <i>
                    Vairavan, S., Rashidisabet, H., Li, Q., Ness, S., Morrison, R., Soares, C., Uher, R., Frey, B., Lam, R., Kennedy, S., Trivedi, M., Drevets, W., Narayan, V.
                  </i>
                  <b>
                      <i>Scientific Reports - Nature</i>
                  </b>
              </div>
            </div>

            <div id="relatedLinks">
                    <!--link-->
                    <a href="https://doi.org/10.1038/s41598-023-44592-8" target="_blank">
                      <i id=activeLink  class="fa">&#xf0c1;</i>
                    </a>
            </div>

              <div id="abstract">
                  <div class="content">
                      <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                      <b> Abstract: </b>
                      Major depressive disorder (MDD) is a chronic illness wherein relapses contribute to significant patient morbidity and mortality. Near-term prediction of relapses in MDD patients has the potential to improve outcomes by helping implement a ‘predict and preempt’ paradigm in clinical care. In this study, we developed a novel personalized (N-of-1) encoder-decoder anomaly detection-based framework of combining anomalies in multivariate actigraphy features (passive) as triggers to utilize an active concurrent self-reported symptomatology questionnaire (core symptoms of depression and anxiety) to predict near-term relapse in MDD. The framework was evaluated on two independent longitudinal observational trials, characterized by regular bimonthly (every other month) in-person clinical assessments, weekly self-reported symptom assessments, and continuous activity monitoring data with two different wearable sensors for ≥ 1 year or until the first relapse episode. This combined passive-active relapse prediction framework achieved a balanced accuracy of ≥ 71%, false alarm rate of ≤ 2.3 alarm/patient/year with a median relapse detection time of 2–3 weeks in advance of clinical onset in both studies. The study results suggest that the proposed personalized N-of-1 prediction framework is generalizable and can help predict a majority of MDD relapses in an actionable time frame with relatively low patient and provider burden.
                    </p>
                  </div>
                  <a role="button" href="#" class="js-show-more">Show more</a>
                </div>
            </div>


            <!--
                        Item
            -->
            <div class="container">
                  <div id="year">
                    <div id="yearItem"> May 2023 </div>
                  </div>
                  <div id="publisher">
                    <div id="publisherItem">   </div>
                  </div>
                  <div id="paperTitle">
                    <div id="paperTitleItem">
                        Which OCT parameters can best predict visual field progression in glaucoma?
                        <i>
                          Sethi, A., Rashidisabet, H., Hallak, J., Vajaranant, T.
                        </i>
                        <b>
                            <i>Eye - Nature</i>
                        </b>
                    </div>
                  </div>

                  <div id="relatedLinks">
                          <!--link-->
                          <a href="https://doi.org/10.1038/s41433-023-02547-3" target="_blank">
                            <i id=activeLink  class="fa">&#xf0c1;</i>
                          </a>
                  </div>

                  <div id="abstract">
                      <div class="content">
                          <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                          <b> Abstract: </b>
                          Which OCT-based parameters are the best predictors for current and future functional damage in glaucoma patients? The answer is that it depends. Overall, RNFLT changes can predict VF progression; however, limitations such as the “floor effect”, myopia,
                          sensitivities to decentration error, thickness changes outside the range of the VF test may prove challenging for accurate monitoring, especially in eyes with advanced glaucoma. Therefore,
                          we propose three clinical implications: (1) Leverage all imaging: utilize RNFL, macular OCT and optic disc evaluation in tandem with VF for glaucoma diagnosis and monitoring. Be mindful that
                          key diagnostic and prognostic parameters, such as disc hemorrhages and pallor, cannot be detected using OCT. (2) OCT macula can be helpful in early detection in eyes with anomalous nerves or
                          myopia and in advanced stage-glaucoma when the RNFL reaches the floor. (3) Future studies can consider OCT angiography to evaluate optic disc perfusion, which could enhance the prognostic prediction, in combination with our current OCT parameters.
                        </p>
                      </div>
                      <a role="button" href="#" class="js-show-more">Show more</a>
                    </div>
                </div>

      <!--
                  Item
      -->
      <div class="container">
            <div id="year">
              <div id="yearItem"> April 2022 </div>
            </div>
            <div id="publisher">
              <div id="publisherItem">   </div>
            </div>
            <div id="paperTitle">
              <div id="paperTitleItem">
                  Revisiting Power-Law Estimation with Applications to Real-World Human Typing Dynamics.
                  <i>
                    Rashidisabet, H., Ajilore, O., Leow, A., Demos, A.
                  </i>
                  <b>
                      <i>Physica A: Statistical Mechanics and its Applications. </i>
                  </b>
              </div>
            </div>

            <div id="relatedLinks">
                    <!--link-->
                    <a href="https://doi.org/10.1016/j.physa.2022.127384" target="_blank">
                      <i id=activeLink  class="fa">&#xf0c1;</i>
                    </a>
            </div>

              <div id="abstract">
                  <div class="content">
                      <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                      <b> Abstract: </b>
                        Ubiquitous use of smartphones has significantly shaped interpersonal communications in modern life, in particular interactions via text messaging. To study the underlying dynamics of these smartphone-based human communications, we used a unique smartphone typing dataset that was passively and unobtrusively collected in-the-wild from 296 users via a custom-made iPhone keyboard. To reliably and accurately characterize the underlying distribution of the inter-event time between two consecutive keypresses, we (i) developed a statistical approach that integrates existing methods for estimating power-law distribution, and (ii) showed that power-law is a plausible candidate to represent human typing dynamics. We designed synthetic-data simulations in multiple scenarios where the synthetic data may or may not imitate human typing characteristics. Using numerical simulations, we showed that our approach, in all scenarios, improves the accuracy and stability of power-law estimates upon the common methods. We further demonstrated that when the synthetic data follow human typing characteristics, common methods lead to significant misestimations of power-law exponent as they fail to take into account the key characteristics of the observed data. More broadly, our approach applies beyond the power-law estimation for human typing dynamics data.
                    </p>
                  </div>
                  <a role="button" href="#" class="js-show-more">Show more</a>
                </div>
            </div>


                <!--
                            Item
                -->
                <div class="container">
                      <div id="year">
                        <div id="yearItem"> April 2020 </div>
                      </div>
                      <div id="publisher">
                        <div id="publisherItem">   </div>
                      </div>
                      <div id="paperTitle">
                        <div id="paperTitleItem">
                            A Systems Biology Approach to the Digital Behaviorome.
                            <i>
                              Rashidisabet, H., Thomas, P., Ajilore, O., Zulueta, J., Moore, R., Leow, A.
                            </i>
                            <b>
                                <i>Elsevier Journal of Current Opinion in Systems Biology. </i>
                            </b>
                        </div>
                      </div>

                      <div id="relatedLinks">
                              <!--link-->
                              <a href="https://doi.org/10.1016/j.coisb.2020.07.003" target="_blank">
                                <i id=activeLink  class="fa">&#xf0c1;</i>
                              </a>
                      </div>

                        <div id="abstract">
                            <div class="content">
                                <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                                <b> Abstract: </b>
                                  This review article summarizes how emerging connected technologies (e.g., smartphones and wearables) may provide
                                  novel avenues to understand an individual's behavior through the lens of systems biology. First, we surveyed
                                  recent research efforts that leveraged the multimodal high temporal resolution data derived from connected devices
                                  to build digital phenotypes and/or discover digital biomarkers of the behaviorome. We write this review with a
                                  particular emphasis on the detection, diagnosis, and symptom monitoring of neuropsychiatric disorders, as these
                                  pathologies may manifest primarily as disruptions to the behaviorome. We then discussed new opportunities and
                                  challenges these state-of-art research efforts bring as they intersect with other areas of natural and social
                                  sciences. Ultimately, we suggest how incorporating systems biology and connected technologies data can lead to
                                  a better understanding of complex neuropsychiatric disorders.
                              </p>
                            </div>
                            <a role="button" href="#" class="js-show-more">Show more</a>
                          </div>
                      </div>

        <!--
                Item
        -->
        <div class="container">
              <div id="year">
                <div id="yearItem"> July 2020 </div>
              </div>
              <div id="publisher">
                <div id="publisherItem">  </div>
              </div>
              <div id="paperTitle">
                <div id="paperTitleItem">
                  Effects of Mood and Aging on Keystroke Dynamics Metadata and Their Diurnal Patterns in A
                  Large Open-Science Sample: A BiAffect iOS Study.
                    <i>
                      Vesel, C., Rashidisabet, H., Zulueta, J., Stange, J., Duffecy, J., Hussain,
                      F., Piscitello, A., Bark, J., Langenecker, S., Young, S., Mounts, E., Omberg, L.,
                      Nelson, P., Moore, R., Koziol, D., Bourne, K., Bennett, C., Ajilore, O., Demos, A., Leow, A.
                    </i>
                    <b>
                        <i>Journal of the American Medical Informatics Association (JAMIA). </i>
                    </b>
                </div>
              </div>

              <div id="relatedLinks">
                      <!--link-->
                      <a href="https://academic.oup.com/jamia/article/27/7/1007/5848291?login=true#:~:text=https%3A//doi.org/10.1093/jamia/ocaa057" target="_blank">
                        <i id=activeLink  class="fa">&#xf0c1;</i>
                      </a>
              </div>

              <div id="abstract">
                  <div class="content">
                    <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                    <b> Abstract: </b>
                    <br />
                    <b> Objective </b>
                    Ubiquitous technologies can be leveraged to construct ecologically relevant metrics that
                    complement traditional psychological assessments. This study aims to determine the feasibility
                    of smartphone-derived real-world keyboard metadata to serve as digital biomarkers of mood.
                    <br />
                    <b> Materials and Methods </b>
                    BiAffect, a real-world observation study based on a freely available iPhone app, allowed the
                    unobtrusive collection of typing metadata through a custom virtual keyboard that replaces the
                    default keyboard. User demographics and self-reports for depression severity (Patient Health
                    Questionnaire-8) were also collected. Using &gt 14 million keypresses from 250 users who reported
                    demographic information and a subset of 147 users who additionally completed at least 1 Patient
                    Health Questionnaire, we employed hierarchical growth curve mixed-effects models to capture the
                    effects of mood, demographics, and time of day on keyboard metadata.
                    <br />
                    <b> Results </b>
                    We analyzed 86 541 typing sessions associated with a total of 543 Patient Health Questionnaires.
                    Results showed that more severe depression relates to more variable typing speed (<i>P</i> < 0.001), shorter
                    session duration (<i>P</i> < .001), and lower accuracy (<i>P</i> < .05). Additionally, typing speed and variability
                    exhibit a diurnal pattern, being fastest and least variable at midday. Older users exhibit slower and
                    more variable typing, as well as more pronounced slowing in the evening. The effects of aging and time
                    of day did not impact the relationship of mood to typing variables and were recapitulated in the 250-user group.
                    <br />
                    <b> Conclusions </b>
                    Keystroke dynamics, unobtrusively collected in the real world, are significantly associated with mood despite
                    diurnal patterns and effects of age, and thus could serve as a foundation for constructing digital biomarkers.
                  </p>
                </div>
                <a role="button" href="#" class="js-show-more">Show more</a>
                </div>
            </div>



    <h3 style="padding:0;margin: 0;font-weight: bold;">Book chapter </h2>
            <!--
                        Item
            -->
            <div class="container">
                  <div id="year">
                    <div id="yearItem"> July 2023 </div>
                  </div>
                  <div id="publisher">
                    <div id="publisherItem">   </div>
                  </div>
                  <div id="paperTitle">
                    <div id="paperTitleItem">
                        Passive Sensing of Affective and Cognitive Functioning in Mood Disorders by Analyzing Keystroke Kinematics and Speech Dynamics.
                        <i>
                          Hussain, F., Stange, J., Langenecker, S., McInnis, M., Zulueta, J., Piscitello, A., Ross, M., Demos, A., Vesel, C., Rashidisabet, H., Cao, B., Huang, H., Yu, P., Nelson, P., Ajilore, O., Leow, A.
                        </i>
                        <b>
                            <i>Digital phenotyping and mobile sensing: New developments in psychoinformatics, pp.161-183</i>
                        </b>
                    </div>
                  </div>

                  <div id="relatedLinks">
                          <!--link-->
                          <a href="https://doi.org/10.1007/978-3-030-98546-2_13" target="_blank">
                            <i id=activeLink  class="fa">&#xf0c1;</i>
                          </a>
                  </div>

                    <div id="abstract">
                        <div class="content">
                            <p class="js-excerpt excerpt-hidden" style="line-height: 1.2em;text-indent: 0px;">
                            <b> Abstract: </b>
                              Mood disorders can be difficult to diagnose, evaluate, and treat. They involve affective and cognitive components, both of which need to be closely monitored over the course of the illness. Current methods like interviews and rating scales can be cumbersome, sometimes ineffective, and oftentimes infrequently administered. Even ecological momentary assessments, when used alone, are susceptible to many of the same limitations and still require active participation from the subject. Passive, continuous, frictionless, and ubiquitous means of recording and analyzing mood and cognition obviate the need for more frequent and lengthier doctor’s visits, can help identify misdiagnoses, and would potentially serve as an early warning system to better manage medication adherence and prevent hospitalizations. Activity trackers and smartwatches have long provided exactly such a tool for evaluating physical fitness. What if smartphones, voice assistants, and eventually Internet of Things devices and ambient computing systems could similarly serve as fitness trackers for the brain, without imposing any additional burden on the user? In this chapter, we explore two such early approaches—an in-depth analytical technique based on examining meta-features of virtual keyboard usage and corresponding typing kinematics, and another method which analyzes the acoustic features of recorded speech—to passively and unobtrusively understand mood and cognition in people with bipolar disorder. We review innovative studies that have used these methods to build mathematical models and machine learning frameworks that can provide deep insights into users’ mood and cognitive states. We then outline future research considerations and conclude with discussing the opportunities and challenges afforded by these modes of researching mood disorders and passive sensing approaches in general.
                          </p>
                        </div>
                        <a role="button" href="#" class="js-show-more">Show more</a>
                      </div>
                  </div>



</div>

<script src="style/scripts.js"></script>
</body>
</html>
